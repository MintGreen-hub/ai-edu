
## 12.4 解决一维非线性问题

我们在前面学习的 SVM 算法都是针对线性可分数据的，下面我们学习如何解决非线性可分的问题。

### 12.1.1 原始问题

我们先看一个简单的例子，假设有 7 个样本，其中 4 个正类样本 $x_{1}=[-1.5,\ -1,\ 1,\ 1.5]$，3 个负类样本 $x_{1}=[-0.5,\ 0,\ 0.5]$，它们都排列在 $x_{1}$ 轴上（即 $x_{2}=0$），如图 12.1.1 的左子图所示。我们无法将这两类样本点做线性分割。

<img src="./images/12-4-1.png" />

<center>图 12.1.1 </center>

### 12.1.2 增加一维新特征

但是，如同前面学习的多项式回归一样，如果令 $x_{2}=x_{1}^2$，则可以得到表 12.1.1 中的数据，也就是说，把一维的特征无形中增加了一维，变成二维的了。

表 12.1.1 增加了一维特征后的样本数据

|样本|$x_{1}$|$x_{2}$|$y$|
|--|--:|:--|--:|
|1|-1.5|2.25|1|
|2|-1.0|1.0|1|
|3|-0.5|0.25|-1|
|4|0.0|0.0|-1|
|5|0.5|0.25|-1|
|6|1.0|1.0|1|
|7|1.5|2.25|1|

上述的过程叫做**映射**，可以定义映射函数为：

$$
f(z)=[z,\ z^2] \tag{12.1.1}
$$

映射函数包含了两个步骤：
1. 先计算原始特征的平方值，即 $z^2$，得到**新特征值**；
2. 把**新特征值**与**原始特征值**拼在一起形成**新的二维特征**。

请读者注意区分**特征**与**特征值**的含义，**特征**是包含了一组**特征值**的向量。

把表 12.1.1 的新生成的样本数据绘制到图 12.1.1 的右图，得到一条抛物线，可以明显看出用一条红色的水平虚线就能够轻松地分开两类样本点。

### 12.1.3 代码验证

为此我们可以做一个简单的试验，完整的代码在 Code_11_4_1_OneDimesion.py 中。

先定义原始数据：

```python
    X_raw = np.array([[-1.5,0], [-1,0], [-0.5,0], [0,0], [0.5,0], [1,0], [1.5,0]])
    Y = np.array([-1,-1,1,1,1,-1,-1])
```
注意，原始数据 X 中，第二维的数据全都是 0，相当于是一维数据。现在把数据从一维变换到二维：

```python
# 把数据从一维变换到二维(x2_new = x1*x1 + x2_origin)
def transform(X_raw):
    X = np.zeros_like(X_raw)
    X[:,0] = X_raw[:,0]
    X[:,1] = X_raw[:,0] ** 2 + X_raw[:,1]
    return X
```

然后使用线性 SVM 分类分类：

```python
# 线性SVM分类器
def linear_svc(X,Y):
    model = SVC(C=3, kernel='linear')
    model.fit(X,Y)
    return model
```

结果如图 12.1.2 所示。

<img src="./images/12-4-2.png" />

<center>图 12.1.2 试验结果</center>

可以看到，在图 12.1.2 左图中，增加一维特征后，父类样本点都升高了，正类样本点升高幅度较小，可以用线性分类器轻松分界，黄色区域被预测为负类，灰色区域被预测为正类。

现在想象把各个样本点的 $x_{2}$ 值都“压回”到原始值（$x_{2}=0$），那么分界线也会随之变化，但不再是直线，而是会变成图 12.1.2 右图的样子，形成一条反向的抛物线，也可以分割正负类样本，但是 SVM 是不能形成这种弯曲的分界线的。

在有些资料中，作者凭着想象把图 12.1.2 右子图的分界线的画成开口向上的曲线，请读者注意，这是不正确的。



### 思考和练习

1. 请通过编程绘制出图 12.1.2 中左图的分类间隔。
2. 完成 1 后，请把分类间隔的上下间隔界线绘制在图 12.1.2 的右图中。
